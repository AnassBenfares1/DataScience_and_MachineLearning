{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## 1: Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections  as mc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "For the first part we use the _income classification_ dataset from [kaggle](https://www.kaggle.com/lodetomasi1995/income-classification). This dataset contains some information about individual people and whether they earn more than $50K or not. Some of the features in the dataset are:\n",
    "\n",
    "> 1. `age` : age of the person.\n",
    "> 2. `workclass`: for which sector does the person work for, e.g, private sector, state\n",
    "> 3. `education`: the last degree the person has received.\n",
    "> 4. `occupation`: type of the job, e.g, services, sales, armed forces, etc.\n",
    "> 5. `race`\n",
    "> 6. `sex`\n",
    "> 7. `native-country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/incom_classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns does this dataset have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base rate\n",
    "What is the base rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important! \n",
    "\n",
    "__For all the questions below, fix the seed of random generators to 72.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train a logistic regression model on this data-set. Use all of the features in the dataset. For the categorical features, encode `education`, `occupation`, and `native-country` with label encoding and the rest with one hot encoding. Split the dataset into 80% training and 20% test set.\n",
    "\n",
    "- what is the train accuracy?\n",
    "\n",
    "- what is the test accuracy?\n",
    "\n",
    "- what is the precision and recall for predicting the income class <=50K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting numerial attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns\n",
    "\n",
    "Encode the columns `workclass`, `race`, and `sex` using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the columns `education`, `occupation`, and `native-country` using label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also encode the labels vector `y` to have \\[0, 1\\] labels instead of \\[<=50K, >50K\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now concatonate all these features (numerical, label encoded, and one-hot encoded) into a single dataframe. You can use `pd.concat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test splitting\n",
    "Now split the data into 80% training and 20% test set. Remember to set the random seed to 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization\n",
    "Standardize the numerical features to have mean zero and standard deviation equal to 1. You can use sklearn `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Finally, train a Logistic Regression model on the processed dataset you just created. Use the following attributes for Logistic Regression.\n",
    "\n",
    "```\n",
    "LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=72)\n",
    "```\n",
    "\n",
    "The module `LogisticRegressionCV` enabels you to train a Logistic Regression model with cross validation. That is, it uses a logistic regression model with L2 regularizer and finds the coefficient of the regularizer (which is the hyper-parameter of the model) by doing cross validation. The attribute `cv` determines how many folds it uses for cross validation. By default it searches for the hyper-parameter in a list of 10 numbers between $10^{-4}$ and $10^4$ (in a logarithmic scale). As you know, using a regularized model improves the generalization ability of your model, in other words, it improves the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the confusion matrix of your classifer for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Text Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "For this part we use the _twitter climate change sentiment dataset_ from [kaggle](https://www.kaggle.com/edqian/twitter-climate-change-sentiment-dataset). The dataset contains tweets related to the climate change topic. Each tweet is labeled as one of the following classes:\n",
    "\n",
    "- `2`(News): the tweet links to factual news about climate change\n",
    "\n",
    "- `1`(Pro): the tweet supports the belief of man-made climate change\n",
    "\n",
    "- `0`(Neutral): the tweet neither supports nor refutes the belief of man-made climate change\n",
    "\n",
    "- `-1`(Anti): the tweet does not believe in man-made climate change\n",
    "\n",
    "\n",
    "Your task is to predict the sentiment of these tweets using the text analytics techniques you have learned in the lab and a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/twitter_sentiment_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### base rate\n",
    "What is the base rate for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing the tweets\n",
    "\n",
    "preprocess the tweets:\n",
    "- remove the stopwords\n",
    "\n",
    "- remove the punctuation marks\n",
    "\n",
    "- lowercase all of the words\n",
    "\n",
    "- lemmatize all of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test splitting\n",
    "Split the dataset into 80% training and 20% test set. Remeber to set the random seed to be 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF feature vectors\n",
    "\n",
    "create the TF-IDF feature vectors for the processed tweetes. These will construct you data features that you will use to train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Now train a logistic regression classifier on the TF-IDF vectors. Use the `LogisticRegression` module (without regularizer) from sklearn with the following attributes:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=72)\n",
    "```\n",
    "\n",
    "We encourage you to make a pipeline that first vectorize the input text and then applies the classifier on the TF-IDF vectors. To do this you can use `Pipeline` from `sklearn.pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "- What is the test accuracy of the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the confusion matrix for this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving your classifier!\n",
    "\n",
    "What could you do more to improve the test accuracy of your classifier? Here's some suggestions:\n",
    "\n",
    "- Use regularized logistic regression and tune the hyper-parameter with cross-validation.\n",
    "\n",
    "- Apply further text preprocessing, e.g, removing the retweets in the form of RT @<user>, removing hashtags, removing duplicate tweets (if any), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
