{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataMining_and_MachineLearning/blob/master/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxw5pdemO2Dv"
      },
      "source": [
        "# Classification\n",
        "\n",
        "## 1: Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqfXqhxZO2Dw"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import collections  as mc\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "sns.set_style(\"white\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOpVui6BO2D4"
      },
      "source": [
        "np.random.seed = 72"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_r8OEQWO2D-"
      },
      "source": [
        "### Load data\n",
        "\n",
        "For the first part we use the _income classification_ dataset from [kaggle](https://www.kaggle.com/lodetomasi1995/income-classification). This dataset contains some information about individual people and whether they earn more than $50K or not. Some of the features in the dataset are:\n",
        "\n",
        "> 1. `age` : age of the person.\n",
        "> 2. `workclass`: for which sector does the person work for, e.g, private sector, state\n",
        "> 3. `education`: the last degree the person has received.\n",
        "> 4. `occupation`: type of the job, e.g, services, sales, armed forces, etc.\n",
        "> 5. `race`\n",
        "> 6. `sex`\n",
        "> 7. `native-country`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK4PJ17YO2D_"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/Assignment2/data/incom_classification.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFCgONOlO2ED"
      },
      "source": [
        "How many rows and columns does this dataset have?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-_kaozO2ED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Pah9iZO2EK"
      },
      "source": [
        "### base rate\n",
        "What is the base rate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqRApkyO2EL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmwUrAPO2EQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv2fyLZ_O2Eg"
      },
      "source": [
        "### Important! \n",
        "\n",
        "__For all the questions below, fix the seed of random generators to 72.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpa2Mre6O2Eh"
      },
      "source": [
        "### Training\n",
        "\n",
        "Train a logistic regression model on this data-set. Use all of the features in the dataset. For the categorical features, encode `education`, `occupation`, and `native-country` with label encoding and the rest with one hot encoding. Split the dataset into 80% training and 20% test set.\n",
        "\n",
        "- what is the train accuracy?\n",
        "\n",
        "- what is the test accuracy?\n",
        "\n",
        "- what is the precision and recall for predicting the income class <=50K?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9k4WN6XO2Eh"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUHmZHuvO2Ek"
      },
      "source": [
        "#### Numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1ftYYjtO2El"
      },
      "source": [
        "# extracting numerial attributes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6zMImp3O2Eq"
      },
      "source": [
        "#### Categorical columns\n",
        "\n",
        "Encode the columns `workclass`, `race`, and `sex` using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcIU-eKrO2Er"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIuV8iakO2Ev"
      },
      "source": [
        "Encode the columns `education`, `occupation`, and `native-country` using label encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4xJFT3pzO2Ew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phnDEP4wO2E5"
      },
      "source": [
        "Also encode the labels vector `y` to have \\[0, 1\\] labels instead of \\[<=50K, >50K\\]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpR_ORKgO2E6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp0r0W7-O2E-"
      },
      "source": [
        "Now concatonate all these features (numerical, label encoded, and one-hot encoded) into a single dataframe. You can use `pd.concat` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxl8_SuJO2E-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmg_xQsYO2FC"
      },
      "source": [
        "#### Train/test splitting\n",
        "Now split the data into 80% training and 20% test set. Remember to set the random seed to 72."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jomLar1OO2FC"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iIW_JaO2FE"
      },
      "source": [
        "#### Standardization\n",
        "Standardize the numerical features to have mean zero and standard deviation equal to 1. You can use sklearn `StandardScaler` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexA_A6bO2FF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RupzHw6XO2FH"
      },
      "source": [
        "#### Training\n",
        "Finally, train a Logistic Regression model on the processed dataset you just created. Use the following attributes for Logistic Regression.\n",
        "\n",
        "```\n",
        "LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=72)\n",
        "```\n",
        "\n",
        "The module `LogisticRegressionCV` enabels you to train a Logistic Regression model with cross validation. That is, it uses a logistic regression model with L2 regularizer and finds the coefficient of the regularizer (which is the hyper-parameter of the model) by doing cross validation. The attribute `cv` determines how many folds it uses for cross validation. By default it searches for the hyper-parameter in a list of 10 numbers between $10^{-4}$ and $10^4$ (in a logarithmic scale). As you know, using a regularized model improves the generalization ability of your model, in other words, it improves the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p5ud6RHO2FH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efSITI3OO2FL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJdTGetvO2FN"
      },
      "source": [
        "#### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc_S8rC1O2FN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCqHH1RLO2FP"
      },
      "source": [
        "Now compute the confusion matrix of your classifer for the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDdXQUeEO2FP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6hFerSdO2FR"
      },
      "source": [
        "## 2: Text Analytics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk20nX8nO2FS"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1OpjBIjO2Fd"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKDxE6n5O2Fh"
      },
      "source": [
        "#### Load the data\n",
        "\n",
        "For this part we use the _twitter climate change sentiment dataset_ from [kaggle](https://www.kaggle.com/edqian/twitter-climate-change-sentiment-dataset). The dataset contains tweets related to the climate change topic. Each tweet is labeled as one of the following classes:\n",
        "\n",
        "- `2`(News): the tweet links to factual news about climate change\n",
        "\n",
        "- `1`(Pro): the tweet supports the belief of man-made climate change\n",
        "\n",
        "- `0`(Neutral): the tweet neither supports nor refutes the belief of man-made climate change\n",
        "\n",
        "- `-1`(Anti): the tweet does not believe in man-made climate change\n",
        "\n",
        "\n",
        "Your task is to predict the sentiment of these tweets using the text analytics techniques you have learned in the lab and a logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XGZnMGbO2Fm"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/Assignment2/data/twitter_sentiment_data.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsPKL9zqO2Fv"
      },
      "source": [
        "#### base rate\n",
        "What is the base rate for this problem?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KLQGULHO2Fw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1c0sZWkO2F0"
      },
      "source": [
        "#### processing the tweets\n",
        "\n",
        "preprocess the tweets:\n",
        "- remove the stopwords\n",
        "\n",
        "- remove the punctuation marks\n",
        "\n",
        "- lowercase all of the words\n",
        "\n",
        "- lemmatize all of the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QKWfqzsO2F4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G65ppf77O2GC"
      },
      "source": [
        "#### Train/test splitting\n",
        "Split the dataset into 80% training and 20% test set. Remeber to set the random seed to be 72."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Eqnr_NO2GC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvrTN3JbO2GE"
      },
      "source": [
        "#### TF-IDF feature vectors\n",
        "\n",
        "create the TF-IDF feature vectors for the processed tweetes. These will construct you data features that you will use to train a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTZNIahOO2GE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrZvIJYDO2GH"
      },
      "source": [
        "#### Training\n",
        "\n",
        "Now train a logistic regression classifier on the TF-IDF vectors. Use the `LogisticRegression` module (without regularizer) from sklearn with the following attributes:\n",
        "\n",
        "```\n",
        "LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=72)\n",
        "```\n",
        "\n",
        "We encourage you to make a pipeline that first vectorize the input text and then applies the classifier on the TF-IDF vectors. To do this you can use `Pipeline` from `sklearn.pipeline`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBSYDbfbO2GH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8TOX-rO2GS"
      },
      "source": [
        "#### Accuracy\n",
        "\n",
        "- What is the test accuracy of the classifier?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t399keFNO2GT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-mBczHkO2GV"
      },
      "source": [
        "Compute the confusion matrix for this classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlCWAKleO2Gc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgwS7A_qO2Ge"
      },
      "source": [
        "#### Improving your classifier!\n",
        "\n",
        "What could you do more to improve the test accuracy of your classifier? Here's some suggestions:\n",
        "\n",
        "- Use regularized logistic regression and tune the hyper-parameter with cross-validation.\n",
        "\n",
        "- Apply further text preprocessing, e.g, removing the retweets in the form of RT @<user>, removing hashtags, removing duplicate tweets (if any), etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG8PXhsTO2Gf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}